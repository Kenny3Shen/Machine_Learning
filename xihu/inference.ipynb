{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:05:48.777020Z",
     "start_time": "2024-03-21T16:05:48.772900Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import re\n",
    "import string\n",
    "import jieba\n",
    "import pandas as pd\n",
    "from tokenizers import (\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 请修改测试集文件名\n",
    "test_dir = 'test.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:05:48.779936Z",
     "start_time": "2024-03-21T16:05:48.777020Z"
    }
   },
   "id": "ca7314ef3715ac2d",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 如测试集中不存在topic列，请使用 test = df[['content']]\n",
    "df = pd.read_csv(test_dir)\n",
    "test = df[['content', 'topic']]\n",
    "#test = df[['content']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:05:48.908563Z",
     "start_time": "2024-03-21T16:05:48.779936Z"
    }
   },
   "id": "ff5e9472577941ce",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_stopword():\n",
    "    with open('baidu_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "        stopwords = set(line.strip() for line in f)\n",
    "    stopwords.update([\"年\",\"月\",\"日\"])\n",
    "    return stopwords\n",
    "\n",
    "def wordopt_cn(text):\n",
    "    # replace punctuation with space\n",
    "    no_punct = re.sub(pattern, ' ', text)\n",
    "    return str(no_punct)\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    return (word for word in words if word not in stopwords)\n",
    "\n",
    "def process_content(content):\n",
    "    content = wordopt_cn(content)\n",
    "    words = jieba.cut(content)\n",
    "    words = remove_stopwords(words)\n",
    "    content = ' '.join(words)\n",
    "    content = re.sub(spaces_pattern, ' ', content)\n",
    "    return content\n",
    "\n",
    "# Precompile the regular expressions\n",
    "punctuation = \"！？｡。＂＃＄％＆＇（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏.\" + string.punctuation\n",
    "pattern = re.compile('[%s]' % re.escape(punctuation))\n",
    "spaces_pattern = re.compile(r'\\s+')\n",
    "stopwords = get_stopword()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:05:48.914047Z",
     "start_time": "2024-03-21T16:05:48.908563Z"
    }
   },
   "id": "97c719af0f4b9ad0",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shens\\AppData\\Local\\Temp\\ipykernel_10144\\2199731547.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['original_content'] = test['content']\n",
      "100%|██████████| 3405/3405 [00:11<00:00, 295.72it/s]\n",
      "C:\\Users\\shens\\AppData\\Local\\Temp\\ipykernel_10144\\2199731547.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['content'] = test['content'].progress_apply(process_content)\n"
     ]
    }
   ],
   "source": [
    "test['original_content'] = test['content']\n",
    "test['content'] = test['content'].progress_apply(process_content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:06:00.434485Z",
     "start_time": "2024-03-21T16:05:48.915254Z"
    }
   },
   "id": "563d74f5ef150668",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def dummy(text):\n",
    "    return text\n",
    "#test=pd.read_csv('test_jieba.csv')\n",
    "vectorizer = joblib.load('vectorizer_v2.pkl')\n",
    "model = joblib.load('ensemble_v2.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:06:00.799349Z",
     "start_time": "2024-03-21T16:06:00.435792Z"
    }
   },
   "id": "2dfff10c72362666"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3405/3405 [00:01<00:00, 1882.87it/s]\n"
     ]
    }
   ],
   "source": [
    "LOWERCASE = False\n",
    "VOCAB_SIZE = 100_000\n",
    "raw_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
    "raw_tokenizer.normalizer = normalizers.Sequence([normalizers.NFC()] + [normalizers.Lowercase()] if LOWERCASE else [])\n",
    "raw_tokenizer.pre_tokenizer = pre_tokenizers.WhitespaceSplit()\n",
    "\n",
    "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=special_tokens)\n",
    "\n",
    "dataset = Dataset.from_pandas(test[['content']])\n",
    "\n",
    "\n",
    "def train_corp_iter():\n",
    "    for i in range(0, len(dataset), 1000):\n",
    "        yield dataset[i: i + 1000][\"content\"]\n",
    "\n",
    "\n",
    "raw_tokenizer.train_from_iterator(train_corp_iter(), trainer=trainer)\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=raw_tokenizer,\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\",\n",
    ")\n",
    "tokenized_texts_test = []\n",
    "\n",
    "for text in tqdm(test['content'].tolist()):\n",
    "    tokenized_texts_test.append(tokenizer.tokenize(text))\n",
    "    \n",
    "tf_test = vectorizer.transform(tokenized_texts_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:06:04.761201Z",
     "start_time": "2024-03-21T16:06:00.800352Z"
    }
   },
   "id": "80530d185e8c729c"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 89679 features, but MultinomialNB is expecting 89394 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[64], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(tf_test)\n\u001B[0;32m      2\u001B[0m prob \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict_proba(tf_test)\n\u001B[0;32m      3\u001B[0m test[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpred\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m pred\n",
      "File \u001B[1;32mf:\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:363\u001B[0m, in \u001B[0;36mVotingClassifier.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    361\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    362\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvoting \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msoft\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 363\u001B[0m     maj \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict_proba(X), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    365\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# 'hard' voting\u001B[39;00m\n\u001B[0;32m    366\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_predict(X)\n",
      "File \u001B[1;32mf:\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:404\u001B[0m, in \u001B[0;36mVotingClassifier.predict_proba\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    390\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute probabilities of possible outcomes for samples in X.\u001B[39;00m\n\u001B[0;32m    391\u001B[0m \n\u001B[0;32m    392\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    400\u001B[0m \u001B[38;5;124;03m    Weighted average probability for each class per sample.\u001B[39;00m\n\u001B[0;32m    401\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    402\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    403\u001B[0m avg \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39maverage(\n\u001B[1;32m--> 404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_collect_probas(X), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_weights_not_none\n\u001B[0;32m    405\u001B[0m )\n\u001B[0;32m    406\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m avg\n",
      "File \u001B[1;32mf:\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:379\u001B[0m, in \u001B[0;36mVotingClassifier._collect_probas\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    377\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_collect_probas\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m    378\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Collect results from clf.predict calls.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 379\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39masarray([clf\u001B[38;5;241m.\u001B[39mpredict_proba(X) \u001B[38;5;28;01mfor\u001B[39;00m clf \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_])\n",
      "File \u001B[1;32mf:\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:379\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    377\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_collect_probas\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m    378\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Collect results from clf.predict calls.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 379\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39masarray([clf\u001B[38;5;241m.\u001B[39mpredict_proba(X) \u001B[38;5;28;01mfor\u001B[39;00m clf \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_])\n",
      "File \u001B[1;32mf:\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:148\u001B[0m, in \u001B[0;36m_BaseNB.predict_proba\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_proba\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m    133\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    134\u001B[0m \u001B[38;5;124;03m    Return probability estimates for the test vector X.\u001B[39;00m\n\u001B[0;32m    135\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;124;03m        order, as they appear in the attribute :term:`classes_`.\u001B[39;00m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 148\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict_log_proba(X))\n",
      "File \u001B[1;32mf:\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:126\u001B[0m, in \u001B[0;36m_BaseNB.predict_log_proba\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;124;03mReturn log-probability estimates for the test vector X.\u001B[39;00m\n\u001B[0;32m    112\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;124;03m    order, as they appear in the attribute :term:`classes_`.\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    125\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 126\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_X(X)\n\u001B[0;32m    127\u001B[0m jll \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_joint_log_likelihood(X)\n\u001B[0;32m    128\u001B[0m \u001B[38;5;66;03m# normalize by P(x) = P(f_1, ..., f_n)\u001B[39;00m\n",
      "File \u001B[1;32mf:\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:579\u001B[0m, in \u001B[0;36m_BaseDiscreteNB._check_X\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_X\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m    578\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 579\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(X, accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m, reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32mf:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:588\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    585\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    587\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m--> 588\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_n_features(X, reset\u001B[38;5;241m=\u001B[39mreset)\n\u001B[0;32m    590\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32mf:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:389\u001B[0m, in \u001B[0;36mBaseEstimator._check_n_features\u001B[1;34m(self, X, reset)\u001B[0m\n\u001B[0;32m    386\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m    388\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_:\n\u001B[1;32m--> 389\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    390\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_features\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features, but \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    391\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis expecting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features as input.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    392\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: X has 89679 features, but MultinomialNB is expecting 89394 features as input."
     ]
    }
   ],
   "source": [
    "pred = model.predict(tf_test)\n",
    "prob = model.predict_proba(tf_test)\n",
    "test[\"pred\"] = pred\n",
    "test[\"prob\"] = prob.max(axis=1)\n",
    "test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:06:05.008453Z",
     "start_time": "2024-03-21T16:06:04.761201Z"
    }
   },
   "id": "fb689736615bfb10"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "diff = test[test['topic'] != test['pred']]\n",
    "diff"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-21T16:06:05.008453Z"
    }
   },
   "id": "30b63f9ee97e01a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test['topic'], test['pred'])\n",
    "precision = precision_score(test['topic'], test['pred'], average='weighted')\n",
    "recall = recall_score(test['topic'], test['pred'], average='weighted')\n",
    "f1 = f1_score(test['topic'], test['pred'], average='weighted')\n",
    "print(f'Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bae231bdfd6fe71"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "low_prob = test[test['prob'] < 0.5]\n",
    "low_prob"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-21T16:06:05.009861Z"
    }
   },
   "id": "8a297b35e6e4e54a",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
